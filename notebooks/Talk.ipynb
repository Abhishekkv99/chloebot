{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/carsonlam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet') \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions.categorical import Categorical\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "import import_ipynb\n",
    "from MoveData import Options, json2datatools, num_batches, nopeak_mask, create_masks\n",
    "from EncoderDecoder import Encoder, Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network as an Agent\n",
    "\n",
    "In this section we will be putting everything together. We learned AI to make AI robots so let finally do that. \n",
    "\n",
    "If you are not using this notebook to learn, change the below variable `teaching` to `False` so that other notebooks can import the functions defined in this notebook without running all the examples, if you are here to learn and interact with the notebook, change it to `True`\n",
    "\n",
    "The cell below you have seen before, we will need the input and output vocabulary fields `infield, outfield` for our demonstration of how a sequence of words is represented by the transformer and the role that probability plays in the model's outputs. Note, for the time being, we are assuming that the vocabulary consists of all the words in the training set, nothing more nothing less, so if since running START_HERE you have added some lines of data, simply retrain the model from START_HERE before moving on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "teaching = True\n",
    "\n",
    "opt = Options(batchsize=2, device = torch.device(\"cpu\"), epochs=25, lr=0.01, \n",
    "              beam_width=3, max_len = 25, save_path = '../saved/weights/model_weights')\n",
    "\n",
    "data_iter, infield, outfield, opt = json2datatools(path='../saved/pairs.json', opt=opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until we built more capabilities into chloe, we will have to reply on a few software tools. The first tool is a tool for expanding chloe's vocabulary without having to learn them from scratch.\n",
    "\n",
    "nltk is the [Natural Language Toolkit](https://www.nltk.org/) that we will be using for things such as synonym matching, that way when you say \"adore\", Chloe knows it means the same thing as \"like\", even if \"adore\" is not in Chloe's vocabulary. \n",
    "\n",
    "Run the cell below to see how we go from string words to integers and how when we cannot find a word in our vocabulary, we try to find a synonym for that word that is in our vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(word, field, explain=False):\n",
    "    syns = wordnet.synsets(word)\n",
    "    for s in syns:\n",
    "        if explain: print('synonym:', s.name())\n",
    "        for l in s.lemmas():\n",
    "            if explain: print('-lemma:', l.name())\n",
    "            if field.vocab.stoi[l.name()] != 0:\n",
    "                if explain: print('found in vocab', l.name())\n",
    "                return field.vocab.stoi[l.name()]\n",
    "    return 0 # if we cannot find a synonym, return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "synonym: fine.n.01\n",
      "-lemma: fine\n",
      "-lemma: mulct\n",
      "-lemma: amercement\n",
      "synonym: ticket.v.01\n",
      "-lemma: ticket\n",
      "-lemma: fine\n",
      "synonym: all_right.s.01\n",
      "-lemma: all_right\n",
      "-lemma: fine\n",
      "-lemma: o.k.\n",
      "-lemma: ok\n",
      "found in vocab ok\n",
      "token =  6\n"
     ]
    }
   ],
   "source": [
    "if teaching:\n",
    "    print('token = ', get_synonym(\"fine\", infield, explain=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function takes your sentence in the form of text and converts it to a sequence of tokens within a torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2tensor(string, inputfield, explain=False):\n",
    "    '''\n",
    "    input:\n",
    "        string (str) input sentence\n",
    "        inputfield a PyTorch torchtext.data.Field object\n",
    "        explain, set this to True if you want to see how the sentence was split \n",
    "    output:\n",
    "        sequence of tokens (torch tensor of integers) shape  \n",
    "    '''\n",
    "    sentence = inputfield.preprocess(string)\n",
    "    if explain: print(sentence)\n",
    "    integer_sequence = []\n",
    "    for tok in sentence:\n",
    "        if inputfield.vocab.stoi[tok] != 0:\n",
    "            integer_sequence.append(inputfield.vocab.stoi[tok])\n",
    "        else:\n",
    "            integer_sequence.append(get_synonym(tok, inputfield))\n",
    "    return torch.LongTensor([integer_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ok', ',', \"aren't\", 'you', 'a', 'robot', '?']\n",
      "tensor([[ 6,  0,  0,  3,  9, 31,  2]])\n"
     ]
    }
   ],
   "source": [
    "input_sequence = string2tensor(\"ok, aren't -you [a robot?\", infield, explain=True)\n",
    "print(input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assemble the Encoder and Decoder into the Transformer, like older sequence to sequence models, Transformers also encode the sentence into vector representations and pass those representations along to the decoder to generate the response/reply/output/translation/etc. The Encoder and Decoder we can use separately such as `model.encoder(arguments)`. The very last part of the transformer is the mapping of each vector in the decoder output to logits for each token in the output vocabulary `output = self.out(d_output)`. There are as many logits as there are tokens in the output vocabulary. In the conceptual diagram we pretend that each decoder output is represented with 4 dimensional vectors and the last linear layer maps this vector to the output vocabulary which is only 5 tokens including the end of sentence `<eos>` token. In a more realistic model, the decoder might output 512 dimensional vectors and the last linear layer maps this vector to the output vocabulary which is a few thousand tokens wide, including words, punctuation marks and the end of sentence, unknown etc tokens. The softmax later on will balance all these logits to sum to 1.0 so that you can treat this as a probability distribution over the vocabulary from which the agent will draw/sample its next word. \n",
    "\n",
    "<img src=\"../saved/images/vec2vocab.png\" height=500 width=600>\n",
    "\n",
    "Define the Transformer class, instantiate a model and load the weights you trained in START_HERE into that model by running the next 2 cells. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, in_vocab_size, out_vocab_size, emb_dim, n_layers, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.decoder = Decoder(out_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.out = nn.Linear(emb_dim, out_vocab_size)\n",
    "    def forward(self, src_seq, trg_seq, src_mask, trg_mask):\n",
    "        e_output = self.encoder(src_seq, src_mask)\n",
    "        d_output = self.decoder(trg_seq, e_output, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim, n_layers, heads, dropout = 32, 3, 8, 0.01 \n",
    "chloe = Transformer(len(infield.vocab), len(outfield.vocab), emb_dim, n_layers, heads, dropout)\n",
    "    \n",
    "chloe.load_state_dict(torch.load(opt.save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk(input_str, chloe, opt):\n",
    "\n",
    "    input_sequence = string2tensor(input_str, infield)\n",
    "    input_mask = (input_sequence != infield.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "    chloe.eval()\n",
    "    encoding = chloe.encoder(input_sequence, input_mask)\n",
    "    init_tok = outfield.vocab.stoi['<sos>'] \n",
    "    decoder_input = torch.LongTensor([[init_tok]])\n",
    "    logprobs = torch.Tensor([[]])\n",
    "    for pos in range(opt.max_len):\n",
    "        decoder_input_mask = nopeak_mask(size=pos+1, opt=opt)\n",
    "        out = chloe.out(chloe.decoder(decoder_input, encoding, input_mask, decoder_input_mask))\n",
    "        softout = F.softmax(out, dim=-1)\n",
    "        distr = Categorical(probs=softout)\n",
    "        action = distr.sample()[:,-1].unsqueeze(0)\n",
    "        logprob = -distr.log_prob(action)[:,-1].unsqueeze(0)\n",
    "        decoder_input = torch.cat((decoder_input, action), dim=1)\n",
    "        logprobs = torch.cat((logprobs, logprob), dim=1)\n",
    "        if outfield.vocab.itos[action] == '<eos>':\n",
    "            de_str = ' '.join([outfield.vocab.itos[tok] for tok in decoder_input[0]])\n",
    "            return decoder_input, de_str, logprobs\n",
    "        \n",
    "    de_str = ' '.join([outfield.vocab.itos[tok] for tok in decoder_input[0]])\n",
    "    return decoder_input, de_str, logprobs\n",
    "\n",
    "\n",
    "\n",
    "#outputs = torch.zeros(1, opt.max_len).long()\n",
    "#print(' '.join([outfield.vocab.itos[tok] for tok in out[0]]))\n",
    "#outfield.vocab.itos[ix]\n",
    "#outfield.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> meowci beaucoup <eos>\n"
     ]
    }
   ],
   "source": [
    "decoder_input, de_str, logprobs = talk(\"how?\", chloe, opt)\n",
    "print(de_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vars(src, model, SRC, TRG, opt):\n",
    "    init_tok = TRG.vocab.stoi['<sos>']\n",
    "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "    e_output = model.encoder(src, src_mask)\n",
    "    outputs = torch.LongTensor([[init_tok]])\n",
    "    if opt.device == torch.device(\"cuda:0\"):\n",
    "        outputs = outputs.cuda()\n",
    "    trg_mask = nopeak_mask(1, opt)\n",
    "    out = model.out(model.decoder(outputs, e_output, src_mask, trg_mask))\n",
    "    out = F.softmax(out, dim=-1)\n",
    "    probs, ix = out[:, -1].data.topk(opt.k)\n",
    "    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n",
    "    outputs = torch.zeros(opt.k, opt.max_len).long()\n",
    "    if opt.device != -1:\n",
    "        outputs = outputs.cuda()\n",
    "    outputs[:, 0] = init_tok\n",
    "    outputs[:, 1] = ix[0]\n",
    "    e_outputs = torch.zeros(opt.k, e_output.size(-2),e_output.size(-1))\n",
    "    if opt.device != -1:\n",
    "        e_outputs = e_outputs.cuda()\n",
    "    e_outputs[:, :] = e_output[0]\n",
    "    return outputs, e_outputs, log_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 14,  4,  3],\n",
      "        [ 2, 18,  4,  3],\n",
      "        [ 2,  8,  4,  3],\n",
      "        [ 2,  9, 16,  3]], device='cuda:0') torch.Size([4, 4]) 1\n"
     ]
    }
   ],
   "source": [
    "def k_best_outputs(outputs, out, log_scores, i, k):\n",
    "    probs, ix = out[:, -1].data.topk(k)\n",
    "    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n",
    "    k_probs, k_ix = log_probs.view(-1).topk(k)\n",
    "    row = k_ix // k\n",
    "    col = k_ix % k\n",
    "    outputs[:, :i] = outputs[row, :i]\n",
    "    outputs[:, i] = ix[row, col]\n",
    "    log_scores = k_probs.unsqueeze(0)\n",
    "    return outputs, log_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def beam_search(src, model, SRC, TRG, opt):\n",
    "    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, opt)\n",
    "    eos_tok = TRG.vocab.stoi['<eos>']\n",
    "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "    ind = None\n",
    "    for i in range(2, opt.max_len):\n",
    "        trg_mask = nopeak_mask(i, opt)\n",
    "        out = model.out(model.decoder(outputs[:,:i], e_outputs, src_mask, trg_mask))\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, opt.k)\n",
    "        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n",
    "        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).cuda()\n",
    "        for vec in ones:\n",
    "            i = vec[0]\n",
    "            if sentence_lengths[i]==0: # First end symbol has not been found yet\n",
    "                sentence_lengths[i] = vec[1] # Position of first end symbol\n",
    "        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n",
    "        if num_finished_sentences == opt.k:\n",
    "            alpha = 0.7\n",
    "            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n",
    "            _, ind = torch.max(log_scores * div, 1)\n",
    "            ind = ind.data[0]\n",
    "            break\n",
    "    if ind is None:\n",
    "        print(outputs[0]==eos_tok)\n",
    "        print((outputs[0]==eos_tok).nonzero())\n",
    "        length = (outputs[0]==eos_tok).nonzero()[0]\n",
    "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n",
    "    else:\n",
    "        length = (outputs[ind]==eos_tok).nonzero()[0]\n",
    "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_to_model(sentence, model, opt, SRC, TRG):\n",
    "    model.eval()\n",
    "    indexed = []\n",
    "    sentence = SRC.preprocess(sentence)\n",
    "    for tok in sentence:\n",
    "        if SRC.vocab.stoi[tok] != 0:\n",
    "            indexed.append(SRC.vocab.stoi[tok])\n",
    "        else:\n",
    "            indexed.append(get_synonym(tok, SRC))\n",
    "    sentence = Variable(torch.LongTensor([indexed]))\n",
    "    if opt.device != -1:\n",
    "        sentence = sentence.cuda()\n",
    "    sentence = beam_search(sentence, model, SRC, TRG, opt)\n",
    "    return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(dict, text):\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]], device='cuda:0') torch.Size([4, 4])\n",
      "tensor([[[True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True]]], device='cuda:0') torch.Size([4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "torch.CharTensor(2, 3).unsqueeze(-1).shape\n",
    "init_tok = outfield.vocab.stoi['<sos>'] # 2 (int) \n",
    "input_mask = batch != infield.vocab.stoi['<pad>'] # tensor([[True, True, True, True, True, True, True, True]])\n",
    "print(input_mask.shape)\n",
    "input_mask = input_mask.unsqueeze(-2)\n",
    "print(input_mask.shape)\n",
    "e_output = model.encoder(batch, input_mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
