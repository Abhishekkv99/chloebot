{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/carson/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from MoveData.ipynb\n",
      "importing Jupyter notebook from Encoder.ipynb\n",
      "importing Jupyter notebook from Elements.ipynb\n",
      "importing Jupyter notebook from Decoder.ipynb\n"
     ]
    }
   ],
   "source": [
    "import re, math\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet') \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F \n",
    "import import_ipynb\n",
    "from MoveData import Options, csv2datatools\n",
    "from Encoder import Encoder\n",
    "from Decoder import Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ", the one below imports `torch` so you can use PyTorch, it also imports some python code that I wrote in the folder *scripts* that I will explain to you after I show you a toy example of how the whole code works together, using a chatbot that says cute/flirty/snide/anything you want/etc language. nltk is the [Natural Language Toolkit](https://www.nltk.org/) that we will be using for things such as synonym matching, that way when you say \"adore\", Chloe knows it means the same thing as \"like\", even if \"adore\" is not in Chloe's vocabulary. To do this nltk will need to download a folder called corpora. Running the next cell will do that for you.\n",
    "\n",
    "\n",
    "The cell below you have seen before, we will need the input and output vocabulary fields `infield, outfield` for our demonstration of how a sequence of words is represented by the transformer and the role that probability plays in the model's outputs. remove the triple quotes ''' code goes here ''' and run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../saved/chat_pairs.csv'\n",
    "opt = Options(batchsize = 4)\n",
    "data_iter, infield, outfield, opt = csv2datatools(csv_path,'en', opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uncomment the last line and Run the cell below to see how we go from string words to integers and how when we cannot find a word in our vocabulary, we try to find a synonym for that word that is in our vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(word, field, explain=False):\n",
    "    syns = wordnet.synsets(word)\n",
    "    for s in syns:\n",
    "        if explain: print('synonym:', s.name())\n",
    "        for l in s.lemmas():\n",
    "            if explain: print('-lemma:', l.name())\n",
    "            if field.vocab.stoi[l.name()] != 0:\n",
    "                if explain: print('found in vocab', l.name())\n",
    "                return field.vocab.stoi[l.name()]\n",
    "    return 0 # if we cannot find a synonym, return 0\n",
    "\n",
    "#print('token = ', get_synonym(\"fine\", infield, explain=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we mentioned before, one ability, or limitation depending on how you look at it, of chloe is her fixed vocabulary, each word or symbol in her vocabulary is assigned an integer. For example the word hi is assigned 3, the word dog is 17, a word not in the vocabulary is 0,this integer is the `token` output of the `get_synonym` function below. \n",
    "\n",
    "The neural nework sees every word as a vector. [A vector of 3 real numbers forms the coordinates in 3D space](https://youtu.be/fNk_zzaMoSs), we use several more dimensions than 3 in this example,  if we use 512 dimensions, this means that each word is a point in 512 dimensional space, but the same concepts apply to 3D space in that the location of that word in 3D space tells you it's [meaning and meaning relative to other words](https://youtu.be/8rXD5-xhemo?t=1550).\n",
    "\n",
    "<img src=\"../saved/images/wordvectors.png\" height=400 width=400>\n",
    "\n",
    "In the image you see that similar words are close to each other, not only that, the direction they are separated from eachother also carries meaning. In the image, there are 3 clusters of words and the separation between them has something to do with age. If you stack all the vectors on top of eachother row by row, you get a matrix. Remember how each word is represented by both a vector and an integer? well this integer is the index for a row in the matrix. The matrix is called the embedding matrix. you might say that we \"embed\" words into the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def string2tensor(string, inputfield, explain=False):\n",
    "    sentence = inputfield.preprocess(string)\n",
    "    if explain: print(sentence)\n",
    "    integer_sequence = []\n",
    "    for tok in sentence:\n",
    "        if inputfield.vocab.stoi[tok] != 0:\n",
    "            integer_sequence.append(inputfield.vocab.stoi[tok])\n",
    "        else:\n",
    "            integer_sequence.append(get_synonym(tok, inputfield))\n",
    "    return torch.LongTensor([integer_sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ok', ',', 'are', \"n't\", 'you', 'a', 'robot', '?']\n",
      "tensor([[10,  0,  7,  0,  5, 12, 26,  6]])\n"
     ]
    }
   ],
   "source": [
    "input_sequence = string2tensor(\"ok, aren't -you [a robot?\", infield, explain=True)\n",
    "print(input_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take our first look inside the Transformer, like older sequence to sequence models, Transformers also encode the sentence into vector representations and pass those representations along to the decoder to generate the response/reply/output/translation/etc. The Encoder and Decoder have subcomponents that we will discuss later. For now, just know that we can use the different parts to the transformer separately such as `model.encoder(arguments)` define Transformer class, instantiate a model and load the weights you trained in START_HERE into that model by running the next 2 cells. Note, for the time being, we are assuming that the vocabulary consists all all the words in the training set, nothing more nothing less, so if since running START_HERE you have added some lines of data, simply retrain the model from STAT_HERE before moving on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, in_vocab_size, out_vocab_size, emb_dim, n_layers, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.decoder = Decoder(out_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.out = nn.Linear(emb_dim, out_vocab_size)\n",
    "    def forward(self, src_seq, trg_seq, src_mask, trg_mask):\n",
    "        e_output = self.encoder(src_seq, src_mask)\n",
    "        d_output = self.decoder(trg_seq, e_output, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim, n_layers, heads, dropout = 64, 2, 8, 0.1 \n",
    "opt.save_path = '../saved/weights/model_weights'\n",
    "\n",
    "model = Transformer(len(infield.vocab), len(outfield.vocab), emb_dim, n_layers, heads, dropout)\n",
    "\n",
    "if opt.device != -1:\n",
    "    model = model.cuda()\n",
    "    \n",
    "model.load_state_dict(torch.load(opt.save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f7c77a72630>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             '<sos>': 2,\n",
       "             '<eos>': 3,\n",
       "             'chloe': 4,\n",
       "             'you': 5,\n",
       "             '?': 6,\n",
       "             'are': 7,\n",
       "             'bye': 8,\n",
       "             'i': 9,\n",
       "             'ok': 10,\n",
       "             'later': 11,\n",
       "             'a': 12,\n",
       "             'alive': 13,\n",
       "             'cya': 14,\n",
       "             'do': 15,\n",
       "             'dunno': 16,\n",
       "             'go': 17,\n",
       "             'goodbye': 18,\n",
       "             'goodnight': 19,\n",
       "             'got': 20,\n",
       "             'hello': 21,\n",
       "             'hi': 22,\n",
       "             'how': 23,\n",
       "             'ill': 24,\n",
       "             'm': 25,\n",
       "             'robot': 26,\n",
       "             'see': 27,\n",
       "             'ta': 28,\n",
       "             'talk': 29,\n",
       "             'think': 30,\n",
       "             'to': 31,\n",
       "             'true': 32,\n",
       "             'ttyl': 33,\n",
       "             'what': 34,\n",
       "             'who': 35,\n",
       "             'why': 36,\n",
       "             ',': 0,\n",
       "             \"n't\": 0})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infield.vocab.stoi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2, 14,  4,  3],\n",
      "        [ 2, 18,  4,  3],\n",
      "        [ 2,  8,  4,  3],\n",
      "        [ 2,  9, 16,  3]], device='cuda:0') torch.Size([4, 4]) 1\n"
     ]
    }
   ],
   "source": [
    "batch = next(iter(data_iter)).input_text.transpose(0,1)\n",
    "print(batch, batch.shape, infield.vocab.stoi['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]], device='cuda:0') torch.Size([4, 4])\n",
      "tensor([[[True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True]],\n",
      "\n",
      "        [[True, True, True, True]]], device='cuda:0') torch.Size([4, 1, 4])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init_tok = outfield.vocab.stoi['<sos>'] # 2 (int) \n",
    "input_mask = batch != infield.vocab.stoi['<pad>'] # tensor([[True, True, True, True, True, True, True, True]])\n",
    "print(input_mask.shape)\n",
    "input_mask = input_mask.unsqueeze(-2)\n",
    "print(input_mask.shape)\n",
    "e_output = model.encoder(batch, input_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.CharTensor(2, 3).unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_vars(src, model, SRC, TRG, opt):\n",
    "    init_tok = TRG.vocab.stoi['<sos>']\n",
    "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "    e_output = model.encoder(src, src_mask)\n",
    "    outputs = torch.LongTensor([[init_tok]])\n",
    "    if opt.device != -1:\n",
    "        outputs = outputs.cuda()\n",
    "    trg_mask = nopeak_mask(1, opt)\n",
    "    out = model.out(model.decoder(outputs, e_output, src_mask, trg_mask))\n",
    "    out = F.softmax(out, dim=-1)\n",
    "    probs, ix = out[:, -1].data.topk(opt.k)\n",
    "    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0)\n",
    "    outputs = torch.zeros(opt.k, opt.max_len).long()\n",
    "    if opt.device != -1:\n",
    "        outputs = outputs.cuda()\n",
    "    outputs[:, 0] = init_tok\n",
    "    outputs[:, 1] = ix[0]\n",
    "    e_outputs = torch.zeros(opt.k, e_output.size(-2),e_output.size(-1))\n",
    "    if opt.device != -1:\n",
    "        e_outputs = e_outputs.cuda()\n",
    "    e_outputs[:, :] = e_output[0]\n",
    "    return outputs, e_outputs, log_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_best_outputs(outputs, out, log_scores, i, k):\n",
    "    probs, ix = out[:, -1].data.topk(k)\n",
    "    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1) + log_scores.transpose(0,1)\n",
    "    k_probs, k_ix = log_probs.view(-1).topk(k)\n",
    "    row = k_ix // k\n",
    "    col = k_ix % k\n",
    "    outputs[:, :i] = outputs[row, :i]\n",
    "    outputs[:, i] = ix[row, col]\n",
    "    log_scores = k_probs.unsqueeze(0)\n",
    "    return outputs, log_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(src, model, SRC, TRG, opt):\n",
    "    outputs, e_outputs, log_scores = init_vars(src, model, SRC, TRG, opt)\n",
    "    eos_tok = TRG.vocab.stoi['<eos>']\n",
    "    src_mask = (src != SRC.vocab.stoi['<pad>']).unsqueeze(-2)\n",
    "    ind = None\n",
    "    for i in range(2, opt.max_len):\n",
    "        trg_mask = nopeak_mask(i, opt)\n",
    "        out = model.out(model.decoder(outputs[:,:i], e_outputs, src_mask, trg_mask))\n",
    "        out = F.softmax(out, dim=-1)\n",
    "        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, opt.k)\n",
    "        ones = (outputs==eos_tok).nonzero() # Occurrences of end symbols for all input sentences.\n",
    "        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).cuda()\n",
    "        for vec in ones:\n",
    "            i = vec[0]\n",
    "            if sentence_lengths[i]==0: # First end symbol has not been found yet\n",
    "                sentence_lengths[i] = vec[1] # Position of first end symbol\n",
    "        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n",
    "        if num_finished_sentences == opt.k:\n",
    "            alpha = 0.7\n",
    "            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n",
    "            _, ind = torch.max(log_scores * div, 1)\n",
    "            ind = ind.data[0]\n",
    "            break\n",
    "    if ind is None:\n",
    "        print(outputs[0]==eos_tok)\n",
    "        print((outputs[0]==eos_tok).nonzero())\n",
    "        length = (outputs[0]==eos_tok).nonzero()[0]\n",
    "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[0][1:length]])\n",
    "    else:\n",
    "        length = (outputs[ind]==eos_tok).nonzero()[0]\n",
    "        return ' '.join([TRG.vocab.itos[tok] for tok in outputs[ind][1:length]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talk_to_model(sentence, model, opt, SRC, TRG):\n",
    "    model.eval()\n",
    "    indexed = []\n",
    "    sentence = SRC.preprocess(sentence)\n",
    "    for tok in sentence:\n",
    "        if SRC.vocab.stoi[tok] != 0:\n",
    "            indexed.append(SRC.vocab.stoi[tok])\n",
    "        else:\n",
    "            indexed.append(get_synonym(tok, SRC))\n",
    "    sentence = Variable(torch.LongTensor([indexed]))\n",
    "    if opt.device != -1:\n",
    "        sentence = sentence.cuda()\n",
    "    sentence = beam_search(sentence, model, SRC, TRG, opt)\n",
    "    return  multiple_replace({' ?' : '?',' !':'!',' .':'.','\\' ':'\\'',' ,':','}, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(dict, text):\n",
    "  # Create a regular expression  from the dictionary keys\n",
    "  regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, dict.keys())))\n",
    "  # For each match, look-up corresponding value in dictionary\n",
    "  return regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
