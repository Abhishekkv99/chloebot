{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from MoveData.ipynb\n",
      "importing Jupyter notebook from Encoder.ipynb\n",
      "importing Jupyter notebook from Elements.ipynb\n",
      "importing Jupyter notebook from Decoder.ipynb\n",
      "importing Jupyter notebook from LearningDynamics.ipynb\n"
     ]
    }
   ],
   "source": [
    "import time, sys\n",
    "sys.path.append('/media/carson/New Volume/Chloe/chloebot/env36/lib/python3.6/site-packages')\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import import_ipynb\n",
    "from MoveData import Options, json2datatools, num_batches, nopeak_mask, create_masks\n",
    "from Encoder import Encoder\n",
    "from Decoder import Decoder\n",
    "from LearningDynamics import CosineWithRestarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you have 2 GPUs\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"you have\", torch.cuda.device_count(), \"GPUs\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    print('no GPUs detected')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "opt = Options(batchsize=2, device=device, epochs=25, lr=0.01, \n",
    "              beam_width=3, max_len = 25, save_path = '../saved/weights/model_weights')\n",
    "\n",
    "data_iter, infield, outfield, opt = json2datatools(path='../saved/pairs.json',opt=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, in_vocab_size, out_vocab_size, emb_dim, n_layers, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.decoder = Decoder(out_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.out = nn.Linear(emb_dim, out_vocab_size)\n",
    "    def forward(self, src_seq, trg_seq, src_mask, trg_mask):\n",
    "        e_output = self.encoder(src_seq, src_mask)\n",
    "        d_output = self.decoder(trg_seq, e_output, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_dim, n_layers, heads, dropout = 32, 3, 8, 0.01 \n",
    "chloe = Transformer(len(infield.vocab), len(outfield.vocab), emb_dim, n_layers, heads, dropout)\n",
    "chloe.load_state_dict(torch.load(opt.save_path))\n",
    "if opt.device == torch.device(\"cuda:0\"):\n",
    "    chloe =  chloe.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(chloe.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(chloe.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = CosineWithRestarts(optimizer, T_max=num_batches(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(data_iter))\n",
    "src = batch.listen.transpose(0,1)\n",
    "trg = batch.reply.transpose(0,1)\n",
    "trg_input = trg[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f5c2daea2e8>>, {'<unk>': 0, '<pad>': 1, '?': 2, 'you': 3, 'chloe': 4, 'i': 5, 'ok': 6, 'are': 7, 'hi': 8, 'a': 9, 'bye': 10, 'haha': 11, 'hello': 12, 'how': 13, 'later': 14, 'lol': 15, 'sure': 16, 'alive': 17, 'am': 18, 'any': 19, 'do': 20, 'dont': 21, 'dunno': 22, 'go': 23, 'gotta': 24, 'ill': 25, 'im': 26, 'joke': 27, 'know': 28, 'me': 29, 'more': 30, 'robot': 31, 'see': 32, 'talk': 33, 'tell': 34, 'think': 35, 'to': 36, 'true': 37, 'ttyl': 38, 'vicki': 39, 'what': 40, 'who': 41})\n",
      " ------------------------------------------------------ \n",
      "input_vocab_size= 42 , output_vocab_size= 66\n",
      " ------------------------------------------------------ \n",
      "tensor([[34, 29,  9, 27,  4,  1],\n",
      "        [40, 20,  3, 35,  4,  2]], device='cuda:0') torch.Size([2, 6])\n",
      " ------------------------------------------------------ \n",
      "tensor([[ 2, 17, 14, 15, 13, 10, 18,  4,  5,  3,  1],\n",
      "        [ 2, 51, 40, 25, 47,  6, 53, 58, 25, 52,  3]], device='cuda:0') torch.Size([2, 11])\n"
     ]
    }
   ],
   "source": [
    "print(infield.vocab.stoi)\n",
    "print(\" ------------------------------------------------------ \")\n",
    "print('input_vocab_size =', len(infield.vocab), ', output_vocab_size =', len(outfield.vocab))\n",
    "print(\" ------------------------------------------------------ \")\n",
    "print(src, src.shape)\n",
    "print(\" ------------------------------------------------------ \")\n",
    "print(trg, trg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the source mask is (batch_size, 1, input_sequence_length)\n",
    "The shape of the target mask is (batch_size, output_sequence_length, output_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ True,  True,  True,  True,  True, False]],\n",
      "\n",
      "        [[ True,  True,  True,  True,  True,  True]]], device='cuda:0') torch.Size([2, 1, 6])\n",
      " --------------------------------------- \n",
      "tensor([[[ True, False, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[ True, False, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True, False, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
      "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]],\n",
      "       device='cuda:0') torch.Size([2, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "src_mask, trg_mask = create_masks(src, trg_input, opt)\n",
    "print(src_mask, src_mask.shape)\n",
    "print(\" ------------------------------------------------------ \")\n",
    "print(trg_mask, trg_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the source mask is (batch_size, output_sequence_length, output_vocab_size)\n",
    "For every reply in batch_size, chloe says output_sequence_length number of words, for each output position, 66 numbers are given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.6977, -1.1294, -0.7040,  ..., -1.9627,  2.2752, -0.6955],\n",
      "         [-0.5120, -1.4015, -2.1118,  ..., -0.5819, -3.7025, -1.4250],\n",
      "         [-1.7567, -2.1324, -1.2924,  ..., -2.0275, -2.6420,  1.3241],\n",
      "         ...,\n",
      "         [-1.0377, -1.1146, -2.0184,  ...,  3.0106, -2.6459, -1.0744],\n",
      "         [-3.4373, -3.3411, -2.9979,  ..., -5.4473, -1.8967, -3.1632],\n",
      "         [-2.5257, -1.4176, -1.6269,  ..., -4.0867,  2.6793, -2.8859]],\n",
      "\n",
      "        [[-1.2958, -1.0706, -0.5325,  ..., -0.1642,  1.6314, -0.8045],\n",
      "         [ 0.6351, -0.6384,  0.3854,  ...,  2.7451, -1.7780,  1.9991],\n",
      "         [-2.2120, -1.2582, -1.9899,  ..., -2.3293,  1.4207,  0.5253],\n",
      "         ...,\n",
      "         [-2.5363, -1.2725, -2.0955,  ..., -2.0993,  0.9256,  0.2223],\n",
      "         [ 0.8198,  0.4271,  1.5342,  ...,  0.7719,  2.0581, -4.2233],\n",
      "         [-2.9531, -2.4199, -2.5831,  ..., -4.2000, -2.0004, -3.3899]]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>) torch.Size([2, 10, 66])\n"
     ]
    }
   ],
   "source": [
    "preds = chloe(src, trg_input, src_mask, trg_mask)\n",
    "print(preds, preds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(model, data_iterator, options, optimizer, scheduler):\n",
    "\n",
    "    if torch.cuda.is_available() and options.device == torch.device(\"cuda:0\"):\n",
    "        print(\"a GPU was detected, model will be trained on GPU\")\n",
    "        model = model.cuda()\n",
    "    else:\n",
    "        print(\"training on cpu\")\n",
    "\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    best_loss = 100\n",
    "    for epoch in range(options.epochs):\n",
    "        total_loss = 0\n",
    "        for i, batch in enumerate(data_iterator): \n",
    "            src = batch.listen.transpose(0,1)\n",
    "            trg = batch.reply.transpose(0,1)\n",
    "            trg_input = trg[:, :-1]\n",
    "            src_mask, trg_mask = create_masks(src, trg_input, options)\n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            ys = trg[:, 1:].contiguous().view(-1)\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss = F.cross_entropy(preds.view(-1, preds.size(-1)), \n",
    "                                         ys, ignore_index = options.trg_pad)\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            total_loss += batch_loss.item()\n",
    "\n",
    "        epoch_loss = total_loss/(num_batches(data_iterator)+1)\n",
    "        if epoch_loss < best_loss:\n",
    "            best_loss = epoch_loss\n",
    "            torch.save(model.state_dict(), options.save_path)\n",
    "        print(\"%dm: epoch %d loss = %.3f\" %((time.time() - start)//60, epoch, epoch_loss))\n",
    "        total_loss = 0\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
