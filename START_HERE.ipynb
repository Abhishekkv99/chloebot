{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purpose of creating a playground-like teaching and learning environment, all the code used here is stored in a ipython or jupyter notebook. import_ipynb is used to import classes and functions from other notebooks. Since these imports will run all the cells in the notebook you are importing from, once you have finished playing with a certain module or cell in a notebook, comment out the cells you would rather not have executed when the notebook is imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, copy\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import import_ipynb\n",
    "from notebooks.Data_mover import csv2datatools, Options, num_batches\n",
    "from notebooks.Encoder import Encoder \n",
    "from notebooks.Decoder import Decoder \n",
    "from notebooks.Trainer import trainer, CosineWithRestarts\n",
    "from notebooks.Talk import talk_to_model\n",
    "\n",
    "import nltk\n",
    "# for synonym finding, nltk needs to download a folder called corpora to your computer, \n",
    "# change corpora_path to your prefered folder, '../' will put it in the parent folder\n",
    "corpora_path = '../'\n",
    "nltk.download('wordnet', corpora_path) \n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Options(batchsize = 4)\n",
    "data_iter, infield, outfield, opt = csv2datatools('saved/translation_pairs.csv','en', opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, in_vocab_size, out_vocab_size, emb_dim, n_layers, heads, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(in_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.decoder = Decoder(out_vocab_size, emb_dim, n_layers, heads, dropout)\n",
    "        self.out = nn.Linear(emb_dim, out_vocab_size)\n",
    "    def forward(self, src_seq, trg_seq, src_mask, trg_mask):\n",
    "        e_output = self.encoder(src_seq, src_mask)\n",
    "        d_output = self.decoder(trg_seq, e_output, src_mask, trg_mask)\n",
    "        output = self.out(d_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_dim, n_layers, heads, dropout = 64, 2, 8, 0.1 \n",
    "opt.save_path = 'saved/weights/model_weights'\n",
    "model = Transformer(len(infield.vocab), len(outfield.vocab), emb_dim, n_layers, heads, dropout)\n",
    "\n",
    "if opt.device != -1:\n",
    "    model = model.cuda()\n",
    "    \n",
    "model.load_state_dict(torch.load(opt.save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.lr = 0.001 #0.0001\n",
    "opt.epochs = 20 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "scheduler = CosineWithRestarts(optimizer, T_max=num_batches(data_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer(model, data_iter, opt, optimizer, scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chloe > i am chloe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentence = \"who are you?\" \n",
    "opt.k = 1\n",
    "opt.max_len = 10\n",
    "sentence = talk_to_model(sentence, model, opt, infield, outfield)\n",
    "print('Chloe > '+ sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You > hi\n",
      "Chloe > hello\n",
      "\n",
      "You > who are you?\n",
      "Chloe > i am chloe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# when you want to turn off this cell, click Kernel->Interrupt \n",
    "while True:\n",
    "    sentence = input(\"You > \")\n",
    "    sentence = talk_to_model(sentence, model, opt, infield, outfield)\n",
    "    print('Chloe > '+ sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
